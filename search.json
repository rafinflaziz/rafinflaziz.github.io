[
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html",
    "href": "posts/youtube_scraping/youtube_scraping.html",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "",
    "text": "YouTube has become one of the largest platforms in the world. In Indonesia itself, YouTube ranks second on the list of the most visited sites. With such a large audience, YouTube provides a huge opportunity for anyone looking to pursue a career in content creation.\nCertainly, there will be many considerations to be faced before creating a content. Understanding trends and audience preferences is crucial, especially on a highly dynamic platform like YouTube.\nTherefore, I will attempt to analyze data from the top 100 YouTubers in Indonesia with the most subscribers. With this analysis, I hope we can gain insights into what kind of contents are trending in Indonesia and identify what creators can do to enhance their channel’s potential.\nThis project is divided into two parts. The first part involves data collection (scraping) and data cleaning, while the second part involves data visualization and analysis. The analysis part can be viewed here.\n\n\n\n\n\n\nCaution\n\n\n\nYou might get different result when you run all the code in this article. This happens because the data source will be changed (or rather, updated) frequently."
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#where-and-how-to-collect-the-data",
    "href": "posts/youtube_scraping/youtube_scraping.html#where-and-how-to-collect-the-data",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "Where and how to collect the data?",
    "text": "Where and how to collect the data?\nTo obtain the data, I could have used the YouTube API. However, due to resource limitations, I ended up using data scraping technique on SocialBlade website to collect the data.\n\n\n\n\n\n\n\nImportant\n\n\n\nAlthough all of these data are available publicly and can be accessed by anyone, I don’t recommend to do the scraping by yourself, as it is against their terms of service."
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#what-data-are-we-looking-for",
    "href": "posts/youtube_scraping/youtube_scraping.html#what-data-are-we-looking-for",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "What data are we looking for?",
    "text": "What data are we looking for?\nWe can gather many kinds of data from this website. However, we will only focus on a few primary pieces of information:\n\nName: The channel’s name\nUpload count: The number of uploaded content\nSubscribers: The number of subscribers\nViews: Total views from all uploaded videos\nTag: The main category of the channel\nDate created: The channel’s creation date\nMonthly views gained: Number of views gained each month\nMonthly subs gained: Number of subscribers gained each month\n\nThese information are present in each of the channel’s page from the earlier top 100 list. For example, this one below is from Jess No Limit’s page.\n\n\nBefore we start, let’s import some packages\n\n\nCode\nimport json\nimport re\nfrom urllib.request import Request, urlopen\nfrom bs4 import BeautifulSoup as bs\nimport pandas as pd\nimport time\nfrom dateutil.parser import parse\n\n\nNow let’s begin!"
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#navigate-the-top-100-list",
    "href": "posts/youtube_scraping/youtube_scraping.html#navigate-the-top-100-list",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "Navigate the top 100 list",
    "text": "Navigate the top 100 list\nFirst, we will navigate to the main page containing the top 100 most subscribed Indonesian channels. In Python, we can do this by sending a request to the URL using urllib.request package.\n\n\nCode\nurl = 'https://socialblade.com/youtube/top/country/id/mostsubscribed'\n\n# optional, might be needed in some cases\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'}\n\nreq = Request(url, headers=headers)\nresponse = urlopen(req)\n\n\nLet’s see if our request was successful (status code 200). If it succeed, we will create a soup variable, which contains the entire HTML for the URL.\n\n\nCode\nif response.getcode() == 200:\n    # parse the HTML content of the page\n    soup = bs(response.read(), 'html.parser')\n    print('Request success!')\n\nelse:\n    print(f\"Failed to retrieve the page. Status code: {response.getcode()}\")\n\n\nRequest success!\n\n\nGreat, we are in! Now, let’s navigate the information page of each channel on this list. To do that, we need to get the url of each channel’s page."
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#get-each-channels-information-page-url",
    "href": "posts/youtube_scraping/youtube_scraping.html#get-each-channels-information-page-url",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "Get each channel’s information page URL",
    "text": "Get each channel’s information page URL\nTo get the URL of each channel’s page, we need to know where is it located in the HTML. Apparently, the URL is located in as a href attribute of an &lt;a&gt; element inside &lt;div&gt; container with attributes style=\"float: left; width: 350px; line-height: 25px;\". For example, see the image below. It shows the URL for Jess No Limit’s channel.\n\nWe can retrieve that information easily using BeautifulSoup.\n\n\nCode\n# get every div containers that have a specific style attribute\ndivs_with_style = soup.find_all(\n    'div', style=\"float: left; width: 350px; line-height: 25px;\")\n\n# to get each channel's url ID,\n# extract value of 'href' attribute in every &lt;a&gt; element inside each div\nchannel_urls = [div.find('a')['href'] for div in divs_with_style]\n\n# print some example\nprint('examples:', channel_urls[:3])\n\n\nexamples: ['/youtube/channel/UCvh1at6xpV1ytYOAzxmqUsA', '/youtube/channel/UC4tS4Q_Cno5JVcIUXxQOOpA', '/youtube/channel/UC4hGmH5sABOA70D4fGb8qNQ']"
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#navigate-information-page-of-each-channel",
    "href": "posts/youtube_scraping/youtube_scraping.html#navigate-information-page-of-each-channel",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "Navigate information page of each channel",
    "text": "Navigate information page of each channel\nHaving acquired the URL for each channel’s information page, we can access it using a similar procedure to the previous one. For example, here is how you would access the information page for Jess No Limit’s channel.\n\n\nCode\nchannel_url = 'https://socialblade.com' + '/youtube/channel/UCvh1at6xpV1ytYOAzxmqUsA'\n\n# optional, might be needed in some cases\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'}\n\nreq = Request(channel_url, headers=headers)\nresponse = urlopen(req)\n\n#| echo: true\nif response.getcode() == 200:\n    # parse the HTML content of the page\n    soup = bs(response.read(), 'html.parser')\n    print('Request success!')\n\nelse:\n    print(f\"Failed to retrieve the page. Status code: {response.getcode()}\")\n\n\nRequest success!"
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#get-the-data",
    "href": "posts/youtube_scraping/youtube_scraping.html#get-the-data",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "Get the data",
    "text": "Get the data\nI will divide this section into two parts, basic data and time series data. The reason is that their structure is different:\n\nChannel’s basic data are one-to-one, meaning that one channel only has one combination of basic data (name, subs, views, etc)\nChannel’s time series data are one-to-many, meaning that one channel has multiple monthly information.\n\n\nBasic data\n\nName\nFor name information, it is located in a &lt;h1&gt; element with style float: left; font-size: 1.4em; font-weight: bold; color:#333; margin: 0px; padding: 0px; margin-right: 5px;. For example, see the image below. It shows the name of Jess No Limit’s channel.\n\nWe can retrieve that information like we did before using BeautifulSoup.\n\n\nCode\n# get first &lt;h1&gt; element that have a specific style attribute\nname = soup.find(\n    'h1', style=\"float: left; font-size: 1.4em; font-weight: bold; color:#333; margin: 0px; padding: 0px; margin-right: 5px;\")\n\n# strip to remove additional spaces\nname = name.text.strip()\n\n# print name result\nprint(f'the name of the channel is {name}.')\n\n\nthe name of the channel is Jess No Limit.\n\n\n\n\nUploads, subs, views, tag, and date\nFor other basic information, it is located in a &lt;span&gt; element with style font-weight: bold;. In addition to that, we have to make sure that we don’t collect country information, because we already know all channels that we are going to visit are from Indonesia. Again, as an example, see the image below.\n\nUsing similar procedure like before, it yields all the basic data that we need.\n\n\nCode\n# get first &lt;h1&gt; element that have a specific style attribute\nname = soup.find(\n    'h1', style=\"float: left; font-size: 1.4em; font-weight: bold; color:#333; margin: 0px; padding: 0px; margin-right: 5px;\")\n\n# strip to remove additional spaces\nname = name.text.strip()\n\n# get all &lt;span&gt; elements that have a specific style attribute\nspans_with_style = soup.find_all('span', style=\"font-weight: bold;\")\nresult_basic = [name] + [span.text for span in spans_with_style if span.text != 'ID']\n\n# print name result\nprint(f'Basic data about this channel: {result_basic}.')\n\n\nBasic data about this channel: ['Jess No Limit', '2,575', '42.8M', '5,347,533,136', 'Entertainment', 'Sep 7th, 2017'].\n\n\n\n\n\nTime series data\nNow for time series data, it’s a bit trickier. Since the monthly chart is interactive, we need to hover to a point to see the number of subs (or views) gained at that point. This means that the moment we enter this page, the number isn’t shown up anywhere. Therefore, we should be looking for the time series data somewhere in the script that’s linked to that chart.\nFor example, here’s what the time series data looks like Jess No Limit’s page.\n\nAs we can see, it contains a list of list, which each inner list consists of two elements: first one for ID and second one for the actual data (in above example, subscribers gained). So how do we find that data using our program?\nFirst we will find all of the &lt;script&gt; element. Let’s see what it looks like.\n\n\nCode\n# find all &lt;script&gt; element\nscript = soup.find_all('script')\n\n# merge all found elements to be single text\nscript = ''.join(str(item) for item in script)\n\nprint(f'script elements (first 200 characters): {script[:200]}')\n\n\n'script elements (first 200 characters): &lt;script type=\"text/javascript\"&gt;var _sf_startpt=(new Date()).getTime()&lt;/script&gt;&lt;script type=\"text/javascript\"&gt;var beforeload = (new Date()).getTime()&lt;/script&gt;&lt;script src=\"//use.fontawesome.com/64cd5ce7'\n\n\nNow, in that text, we want to retrieve all part of the text that is in the form of a 2D list (starts with ‘[[’ and ends with ’]]’). Remember that there will be two chunk of text that matches this criteria: one for monthly gained subs and one for monthly gained views.\n\n\nCode\n# find all part of text that matches this pattern\ndata = re.findall(r'data:\\s*(\\[\\[.*?\\]\\])', script)\n\n# we use json.loads here to convert the text into a list\nsubs_data = json.loads(data[0])\nviews_data = json.loads(data[1])\n\nprint(f'subs data: {subs_data}\\n')\nprint(f'views data: {views_data}')\n\n\nsubs data: [[1698724800000,1400000],[1696046400000,1500000],[1693454400000,2300000],[1690776000000,4700000],[1688097600000,4500000],[1685505600000,800000],[1682827200000,100000],[1680235200000,100000],[1677560400000,100000],[1675141200000,300000],[1672462800000,700000],[1669784400000,100000],[1667188800000,0],[1664510400000,100000],[1661918400000,100000],[1659240000000,0],[1656561600000,0],[1653969600000,300000],[1651291200000,100000],[1648699200000,100000],[1646024400000,100000],[1643605200000,100000],[1640926800000,200000],[1638248400000,300000],[1635652800000,200000],[1632974400000,100000],[1630382400000,200000],[1627704000000,300000],[1625025600000,300000],[1622433600000,400000],[1619755200000,500000],[1617163200000,400000],[1614488400000,700000],[1612069200000,500000],[1609390800000,400000]]\n\nviews data: [[1698724800000,-19801666],[1696046400000,411397220],[1693454400000,435506366],[1690776000000,551439344],[1688097600000,386627362],[1685505600000,65763364],[1682827200000,23496055],[1680235200000,24277175],[1677560400000,38229401],[1675141200000,8254410],[1672462800000,66544745],[1669784400000,18234562],[1667188800000,15043919],[1664510400000,32917405],[1661918400000,10335789],[1659240000000,12288453],[1656561600000,25526169],[1653969600000,76262949],[1651291200000,32441094],[1648699200000,32631614],[1646024400000,40522486],[1643605200000,31444275],[1640926800000,52438812],[1638248400000,63853960],[1635652800000,55090234],[1632974400000,44384186],[1630382400000,62924763],[1627704000000,83710454],[1625025600000,59117171],[1622433600000,97490812],[1619755200000,99810016],[1617163200000,23185815],[1614488400000,75239628],[1612069200000,76170914],[1609390800000,76419152]]\n\n\nNext, we will filter the relevant numbers and put them together into a pair of [subs, views] for each months.\n\n\nCode\n# find all part of text that matches this pattern\ndata = re.findall(r'data:\\s*(\\[\\[.*?\\]\\])', script)\n\n# we use json.loads here to convert the text into a list\nsubs_data = json.loads(data[0])\nviews_data = json.loads(data[1])\n\nresult_time_series = []\n\n# filter it by grabbing the second value,\n# and put them together in `result` variable\nfor subs, views in zip(subs_data, views_data):\n    result_time_series.append([subs[1], views[1]])\n    \nprint(f'result: {result_time_series}')\n\n\nresult: [[1400000, -19801666], [1500000, 411397220], [2300000, 435506366], [4700000, 551439344], [4500000, 386627362], [800000, 65763364], [100000, 23496055], [100000, 24277175], [100000, 38229401], [300000, 8254410], [700000, 66544745], [100000, 18234562], [0, 15043919], [100000, 32917405], [100000, 10335789], [0, 12288453], [0, 25526169], [300000, 76262949], [100000, 32441094], [100000, 32631614], [100000, 40522486], [100000, 31444275], [200000, 52438812], [300000, 63853960], [200000, 55090234], [100000, 44384186], [200000, 62924763], [300000, 83710454], [300000, 59117171], [400000, 97490812], [500000, 99810016], [400000, 23185815], [700000, 75239628], [500000, 76170914], [400000, 76419152]]\n\n\nSo, Jess No Limit gained 1400000 subs and lost 19801666 views in last month (October 2023).\n\n\n\n\n\n\nNote\n\n\n\nA channel can lose views count due to some of their videos were deleted by youtube or by themself."
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#putting-it-all-together",
    "href": "posts/youtube_scraping/youtube_scraping.html#putting-it-all-together",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "Putting it all together",
    "text": "Putting it all together\nLet’s put it all together and make some functions!\n\nget_channel_data returns informations from each channels\nget_all_databasically calls get_channel_data on every channels and return all of the informations collected from each of them.\n\n\n\nCode\ndef get_channel_data(channel_url, headers=None):\n    channel_url = 'https://socialblade.com' + channel_url\n    # send a request to the channel URL\n    req = Request(channel_url, headers=headers)\n    response = urlopen(req)\n\n    # check if the request was successful (status code 200)\n    if response.getcode() == 200:\n        soup = bs(response.read(), 'html.parser')\n\n        # basic\n        name = soup.find(\n            'h1', style=\"float: left; font-size: 1.4em; font-weight: bold; color:#333; margin: 0px; padding: 0px; margin-right: 5px;\")\n        name = name.text.strip()\n\n        spans_with_style = soup.find_all('span', style=\"font-weight: bold;\")\n        result_basic = [name] + \\\n                       [span.text for span in spans_with_style if span.text != 'ID']\n\n        # time series\n        script = soup.find_all('script')\n        script = ''.join(str(item) for item in script)\n\n        data = re.findall(r'data:\\s*(\\[\\[.*?\\]\\])', script)\n        subs_data = json.loads(data[0])\n        views_data = json.loads(data[1])\n\n        result_time_series = []\n\n        for subs, views in zip(subs_data, views_data):\n            result_time_series.append([subs[1], views[1]])\n\n        return result_basic, result_time_series\n\n    else:\n        return(f\"Failed to retrieve the page. Status code: {response.getcode()}\")\n\n\ndef get_all_data(url, headers=None):\n\n    req = Request(url, headers=headers)\n    response = urlopen(req)\n    \n    if response.getcode() == 200:\n\n        soup = bs(response.read(), 'html.parser')\n        divs_with_style = soup.find_all(\n            'div', style=\"float: left; width: 350px; line-height: 25px;\")\n        channel_urls = [div.find('a')['href'] for div in divs_with_style]\n\n        # results\n        result_basic = []\n        result_time_series = []\n\n        for channel_url in channel_urls:\n            # get result of each channels and append it to the results\n            channel_result_basic, channel_result_time_series = get_channel_data(\n                channel_url, headers=headers)\n\n            result_basic.append(channel_result_basic)\n            result_time_series.append(channel_result_time_series)\n\n            # (optional) add a sleep to prevent requests sent too fast\n            time.sleep(0.1)\n\n        return result_basic, result_time_series\n\n    else:\n        return(f\"Failed to retrieve the page. Status code: {response.getcode()}\")\n\n\nYou can execute the code below to call the function and store the data in data_basic and data_time_series.\n\n\nCode\nurl = 'https://socialblade.com/youtube/top/country/id/mostsubscribed'\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'}\n\ndata_basic, data_time_series = get_all_data(url, headers)"
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#basic-data-1",
    "href": "posts/youtube_scraping/youtube_scraping.html#basic-data-1",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "Basic data",
    "text": "Basic data\n\nExamine the data\nIt will be convenient to clean the data before we proceed to analyze it. Let’s examine what can we do to make our data cleaner. First, let’s create a dataframe and ask: What does the data looks like? Do each column have a proper data type?\n\n\nCode\ndf_1 = pd.DataFrame(data_basic,\n             columns=['name', 'upload_count', 'subscribers (million)', 'views', 'tag', 'date_created'])\ndf_1\n\n\n\n\n\n\n\n\n\nname\nupload_count\nsubscribers (million)\nviews\ntag\ndate_created\n\n\n\n\n0\nJess No Limit\n2,575\n42.8M\n5,347,533,136\nEntertainment\nSep 7th, 2017\n\n\n1\nRicis Official\n3,426\n40.4M\n6,811,702,060\nEntertainment\nJan 15th, 2016\n\n\n2\nFrost Diamond\n3,048\n34M\n8,038,993,217\nGames\nJan 22nd, 2014\n\n\n3\nAH\n2,940\n30.8M\n4,638,933,282\nEntertainment\nJan 26th, 2014\n\n\n4\nIndosiar\n24,583\n27.6M\n5,645,575,794\nEntertainment\nSep 23rd, 2013\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n95\nTRI SUAKA CHANNEL\n1,486\n8.13M\n1,005,418,863\nEntertainment\nOct 21st, 2015\n\n\n96\nOura Gaming\n3,721\n8.12M\n2,460,732,171\nGames\nAug 28th, 2017\n\n\n97\nErpan1140\n1,597\n8.11M\n1,652,168,434\nGames\nJan 13th, 2014\n\n\n98\nKananda Widyantara\n851\n8.06M\n637,071,659\nGames\nMar 5th, 2018\n\n\n99\nZhi En\n1,883\n8.06M\n4,795,018,196\nEntertainment\nMay 31st, 2021\n\n\n\n\n100 rows × 6 columns\n\n\n\n\n\nCode\ndf_1.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 100 entries, 0 to 99\nData columns (total 6 columns):\n #   Column                 Non-Null Count  Dtype \n---  ------                 --------------  ----- \n 0   name                   100 non-null    object\n 1   upload_count           100 non-null    object\n 2   subscribers (million)  100 non-null    object\n 3   views                  100 non-null    object\n 4   tag                    100 non-null    object\n 5   date_created           100 non-null    object\ndtypes: object(6)\nmemory usage: 4.8+ KB\n\n\nThere are several problems that we can fix here:\n\nupload_count, subscribers (million), and views should be integer, not object\ndate_created should be datetime, not object\n\n\n\nConvert column dtype\nBefore converting upload_count and views column into an integer column, we should remove the comma separator in each of the entry. We can do that by replacing (instead of removing) these commas with an empty string using str.replace().\nFor subscribers (million), we replace the ‘M’ letter with an empty string.\n\n\nCode\ndf_1['upload_count'] = df_1['upload_count'].str.replace(',', '')\ndf_1['views'] = df_1['views'].str.replace(',', '')\ndf_1['subscribers (million)'] = df_1['subscribers (million)'].str.replace('M', '')\n\n\nThen, we can convert them easily using astype()\n\n\nCode\ndf_1 = df_1.astype({\n    'upload_count': 'int',\n    'subscribers (million)': 'float',\n    'views': 'int64',\n})\n\n\nFor the date_created column, we will also use astype to convert it into a datetime object. However, pandas won’t immediately recognize the format (like “Sep 7th, 2017”) as a date.\nThis is where parse, one of the functions that we imported at the beginning, comes in handy. That function will reformat our date value into a format that astype would recognize. For example, it would transform “Sep 7th, 2017” into “2017-09-07”.\nWe can utilize the method apply() To implement parse for each value in a dataframe column.\n\n\nCode\ndf_1['date_created'] = df_1['date_created'].apply(parse).astype('datetime64[ns]')\n\n\nLet’s check how our dtypes looks like now.\n\n\nCode\ndf_1.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 100 entries, 0 to 99\nData columns (total 6 columns):\n #   Column                 Non-Null Count  Dtype         \n---  ------                 --------------  -----         \n 0   name                   100 non-null    object        \n 1   upload_count           100 non-null    int32         \n 2   subscribers (million)  100 non-null    float64       \n 3   views                  100 non-null    int64         \n 4   tag                    100 non-null    object        \n 5   date_created           100 non-null    datetime64[ns]\ndtypes: datetime64[ns](1), float64(1), int32(1), int64(1), object(2)\nmemory usage: 4.4+ KB\n\n\n\n\nAdd some features\nAlthough we have enough features to begin with, it still can be improved. I can think of two new features to be added.\n\nviews/upload_count: with this new feature, it can tells us the efficiency of a channel in terms of viewers per video. It makes comparing the performance of two channels easier.\nage: to intuitively quantify date_created column into an integer value.\n\n\n\nCode\ndf_1['views/video'] = df_1['views']/(df_1['upload_count'])\nnow = pd.Timestamp('now')\ndf_1['age'] = round((now - df_1['date_created']).dt.days / 365, 1)\n\n\n\n\nCode\ndf_1\n\n\n\n\n\n\n\n\n\nname\nupload_count\nsubscribers (million)\nviews\ntag\ndate_created\nviews/video\nage\n\n\n\n\n0\nJess No Limit\n2575\n42.80\n5347533136\nEntertainment\n2017-09-07\n2.076712e+06\n6.2\n\n\n1\nRicis Official\n3426\n40.40\n6811702060\nEntertainment\n2016-01-15\n1.988238e+06\n7.9\n\n\n2\nFrost Diamond\n3048\n34.00\n8038993217\nGames\n2014-01-22\n2.637465e+06\n9.9\n\n\n3\nAH\n2940\n30.80\n4638933282\nEntertainment\n2014-01-26\n1.577868e+06\n9.8\n\n\n4\nIndosiar\n24583\n27.60\n5645575794\nEntertainment\n2013-09-23\n2.296537e+05\n10.2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n95\nTRI SUAKA CHANNEL\n1486\n8.13\n1005418863\nEntertainment\n2015-10-21\n6.765941e+05\n8.1\n\n\n96\nOura Gaming\n3721\n8.12\n2460732171\nGames\n2017-08-28\n6.613094e+05\n6.3\n\n\n97\nErpan1140\n1597\n8.11\n1652168434\nGames\n2014-01-13\n1.034545e+06\n9.9\n\n\n98\nKananda Widyantara\n851\n8.06\n637071659\nGames\n2018-03-05\n7.486153e+05\n5.7\n\n\n99\nZhi En\n1883\n8.06\n4795018196\nEntertainment\n2021-05-31\n2.546478e+06\n2.5\n\n\n\n\n100 rows × 8 columns"
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#time-series-data-1",
    "href": "posts/youtube_scraping/youtube_scraping.html#time-series-data-1",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "Time series data",
    "text": "Time series data\nFor time series data, each channel must have exacly 35 months (3 years) of record, meaning that there will be 100 x 35 rows in the dataframe.\nHowever, some channels might be created within the last three years and having less than 35 months of record. In this case, we will append zero values to the record for each months where the channels haven’t been created.\nSome channels might also have more than 35 months for some reason (maybe it already contains the record for this month), so we will delete the last record in this case.\n\n\nCode\n# make 35 rows of each names\nnames = df_1['name']\nnew_names = []\nfor name in names:\n    new_names.extend([name]*35)\n\nsubs_gained = []\nviews_gained = []\nfor element in data_time_series:\n    n = len(element)\n    \n    # if it is less than 35 records, append a [0, 0] values to the record\n    if n &lt; 35:\n        extender = [[0, 0] for i in range(35-n)]\n        element.extend(extender)\n        \n    # if it is more than 35 records, remove the last record\n    elif n &gt; 35:\n        element.pop()\n    \n    # separate subs and views information from the record    \n    for subs, views in element:\n        subs_gained.append(subs)\n        views_gained.append(views)\n\n\nLet’s see how the dataframe looks like\n\n\nCode\ndf_2 = pd.DataFrame({\n    'name': new_names,\n    'views_gained': views_gained,\n    'subs_gained': subs_gained,\n})\n\ndf_2\n\n\n\n\n\n\n\n\n\nname\nviews_gained\nsubs_gained\n\n\n\n\n0\nJess No Limit\n-19801666\n1400000\n\n\n1\nJess No Limit\n411397220\n1500000\n\n\n2\nJess No Limit\n435506366\n2300000\n\n\n3\nJess No Limit\n551439344\n4700000\n\n\n4\nJess No Limit\n386627362\n4500000\n\n\n...\n...\n...\n...\n\n\n3495\nZhi En\n99810016\n500000\n\n\n3496\nZhi En\n23185815\n400000\n\n\n3497\nZhi En\n75239628\n700000\n\n\n3498\nZhi En\n76170914\n500000\n\n\n3499\nZhi En\n76419152\n400000\n\n\n\n\n3500 rows × 3 columns\n\n\n\nI think we forgot something: the date! There should be a date column that indicates when the views and subs were gained. Because I do this analysis in November, we will create a 35 months range from December 2020 to October 2023 for each channel.\n\n\nCode\n# create a monthly date range from dec 2020 to oct 2020\ndates = pd.Series(pd.date_range('2020-12','2023-10', \n              freq='MS'))[::-1]\n\n# we multiply it by 100 (the number of channels)\ndates = pd.concat([dates]*100, ignore_index=True)\n\ndf_2['date'] = dates\n\ndf_2\n\n\n\n\n\n\n\n\n\nname\nviews_gained\nsubs_gained\ndate\n\n\n\n\n0\nJess No Limit\n-19801666\n1400000\n2023-10-01\n\n\n1\nJess No Limit\n411397220\n1500000\n2023-09-01\n\n\n2\nJess No Limit\n435506366\n2300000\n2023-08-01\n\n\n3\nJess No Limit\n551439344\n4700000\n2023-07-01\n\n\n4\nJess No Limit\n386627362\n4500000\n2023-06-01\n\n\n...\n...\n...\n...\n...\n\n\n3495\nZhi En\n99810016\n500000\n2021-04-01\n\n\n3496\nZhi En\n23185815\n400000\n2021-03-01\n\n\n3497\nZhi En\n75239628\n700000\n2021-02-01\n\n\n3498\nZhi En\n76170914\n500000\n2021-01-01\n\n\n3499\nZhi En\n76419152\n400000\n2020-12-01\n\n\n\n\n3500 rows × 4 columns"
  },
  {
    "objectID": "posts/youtube_scraping/youtube_scraping.html#merge-the-two-dataframes",
    "href": "posts/youtube_scraping/youtube_scraping.html#merge-the-two-dataframes",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Scraping",
    "section": "Merge the two dataframes",
    "text": "Merge the two dataframes\nLast but not least, merge the two dataframes together to get our final, clean dataframe. This dataframe will be used for visualization and analysis in the next part.\n\n\nCode\ndf = pd.merge(df_1, df_2, left_on='name', right_on='name')\ndf\n\n\n\n\n\n\n\n\n\nname\nupload_count\nsubscribers (million)\nviews\ntag\ndate_created\nviews/video\nage\nviews_gained\nsubs_gained\ndate\n\n\n\n\n0\nJess No Limit\n2575\n42.80\n5347533136\nEntertainment\n2017-09-07\n2.076712e+06\n6.2\n-19801666\n1400000\n2023-10-01\n\n\n1\nJess No Limit\n2575\n42.80\n5347533136\nEntertainment\n2017-09-07\n2.076712e+06\n6.2\n411397220\n1500000\n2023-09-01\n\n\n2\nJess No Limit\n2575\n42.80\n5347533136\nEntertainment\n2017-09-07\n2.076712e+06\n6.2\n435506366\n2300000\n2023-08-01\n\n\n3\nJess No Limit\n2575\n42.80\n5347533136\nEntertainment\n2017-09-07\n2.076712e+06\n6.2\n551439344\n4700000\n2023-07-01\n\n\n4\nJess No Limit\n2575\n42.80\n5347533136\nEntertainment\n2017-09-07\n2.076712e+06\n6.2\n386627362\n4500000\n2023-06-01\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3495\nZhi En\n1883\n8.06\n4795018196\nEntertainment\n2021-05-31\n2.546478e+06\n2.5\n99810016\n500000\n2021-04-01\n\n\n3496\nZhi En\n1883\n8.06\n4795018196\nEntertainment\n2021-05-31\n2.546478e+06\n2.5\n23185815\n400000\n2021-03-01\n\n\n3497\nZhi En\n1883\n8.06\n4795018196\nEntertainment\n2021-05-31\n2.546478e+06\n2.5\n75239628\n700000\n2021-02-01\n\n\n3498\nZhi En\n1883\n8.06\n4795018196\nEntertainment\n2021-05-31\n2.546478e+06\n2.5\n76170914\n500000\n2021-01-01\n\n\n3499\nZhi En\n1883\n8.06\n4795018196\nEntertainment\n2021-05-31\n2.546478e+06\n2.5\n76419152\n400000\n2020-12-01\n\n\n\n\n3500 rows × 11 columns"
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#extract-code-and-water-type",
    "href": "posts/well_water/well_water_analysis.html#extract-code-and-water-type",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Extract Code and Water Type",
    "text": "Extract Code and Water Type\nAs mentioned earlier, the ID values are formatted as Region Code-Water Type-Sample Number. To make the analysis easier, I will extract the region code and water type from the ID value into their own column.\n\n\nCode\n# split the ID value, then get the first string for the region and second string for the type\ndata['Region'] = data['Sampel ID'].str.split('-').str[0]\ndata['Type'] = data['Sampel ID'].str.split('-').str[1]\n\n\n\n\n\n\n\n\n\nTable 2: First three rows of modified data\n\n\n\nSampel ID\nAs\nCd\nCo\nCr\nCu\nFe\nHg\nMn\nPb\nZn\nRegion\nType\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\nMJ-AS-01\n0.0062\n0.0001\n0.0026\n0.0069\n0.0100\n1.6585\n0.0001\n0.3428\n0.0001\n0.1079\nMJ\nAS\n\n\n2\nMJ-AS-03\n0.0212\n0.0006\n0.0001\n0.0070\n0.0077\n3.7910\n0.0001\n0.4119\n0.0119\n0.0309\nMJ\nAS\n\n\n3\nMJ-AS-04\n0.0065\n0.0001\n0.0001\n0.0062\n0.0073\n0.0820\n0.0001\n0.2206\n0.0186\n0.0521\nMJ\nAS\n\n\n\n\n\n\n\n\nGreat. Now let’s check if the new columns were extracted correctly.\n\n\nCode\nprint('Region unique values:', data['Region'].unique())\n\nprint('Type unique values:', data['Type'].unique())\n\n\nRegion unique values: ['MJ' 'BL' 'CP' 'PC' 'PL' 'RC' 'SR']\nType unique values: ['AS' 'ASAM' '08' '11' '12' '13' 'ASAM‐19']\n\n\nNow we have a problem. The type column should only consists of AS or ASAM. As you can see, there’s another value present in this data. Let’s figure out which rows contain these errors.\n\n\nCode\ndata[~data['Sampel ID'].str.split('-').str[1].isin(['AS', 'ASAM'])]\n\n\n\n\n\n\n\nTable 3: Rows contain errors\n\n\n\nSampel ID\nAs\nCd\nCo\nCr\nCu\nFe\nHg\nMn\nPb\nZn\nRegion\nType\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n52\nCP-08-AS\n0.0155\n0.0010\n0.0001\n0.0128\n0.0113\n6.2391\n0.0001\n0.6119\n0.0142\n0.1370\nCP\n08\n\n\n53\nCP-11-ASAM\n0.0190\n0.0009\n0.0001\n0.0172\n0.0106\n0.2971\n0.0001\n0.0250\n0.0151\n0.1104\nCP\n11\n\n\n54\nCP-12-AS\n0.0134\n0.0001\n0.0008\n0.0186\n0.0119\n0.2941\n0.0001\n0.2472\n0.0049\n0.1761\nCP\n12\n\n\n55\nCP-13-AS\n0.0133\n0.0010\n0.0016\n0.0296\n0.0138\n3.1102\n0.0001\n0.4770\n0.0055\n0.1123\nCP\n13\n\n\n70\nCP-ASAM‐19\n0.0023\n0.0010\n0.0001\n0.0135\n0.0311\n0.1585\n0.0001\n0.0893\n0.0001\n0.2647\nCP\nASAM‐19\n\n\n\n\n\n\n\n\nLooks like there are only 5 rows that are problematic. Let’s just fix them manually.\n\n\nCode\ndata.loc[[52, 54, 55], 'Type'] = 'AS'\ndata.loc[[53, 70], 'Type'] = 'ASAM'\n\n\nLet’s see if those rows already been changed.\n\n\nCode\ndata[~data['Sampel ID'].str.split('-').str[1].isin(['AS', 'ASAM'])]\n\n\n\n\n\n\n\nTable 4: Modified rows\n\n\n\nSampel ID\nAs\nCd\nCo\nCr\nCu\nFe\nHg\nMn\nPb\nZn\nRegion\nType\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n52\nCP-08-AS\n0.0155\n0.0010\n0.0001\n0.0128\n0.0113\n6.2391\n0.0001\n0.6119\n0.0142\n0.1370\nCP\nAS\n\n\n53\nCP-11-ASAM\n0.0190\n0.0009\n0.0001\n0.0172\n0.0106\n0.2971\n0.0001\n0.0250\n0.0151\n0.1104\nCP\nASAM\n\n\n54\nCP-12-AS\n0.0134\n0.0001\n0.0008\n0.0186\n0.0119\n0.2941\n0.0001\n0.2472\n0.0049\n0.1761\nCP\nAS\n\n\n55\nCP-13-AS\n0.0133\n0.0010\n0.0016\n0.0296\n0.0138\n3.1102\n0.0001\n0.4770\n0.0055\n0.1123\nCP\nAS\n\n\n70\nCP-ASAM‐19\n0.0023\n0.0010\n0.0001\n0.0135\n0.0311\n0.1585\n0.0001\n0.0893\n0.0001\n0.2647\nCP\nASAM\n\n\n\n\n\n\n\n\nI think everything is fine by now. Next, we will proceed into the visualization part."
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#univariate-eda",
    "href": "posts/well_water/well_water_analysis.html#univariate-eda",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Univariate EDA",
    "text": "Univariate EDA\n\nNumber of Well in Each Region\nIn the dataset, it is important to notice that each region is represented by a relatively similar number of well samples, ranging from 18 samples to 27 samples. This balanced distribution of data across regions ensures that our analysis and clustering results will be relatively robust and unbiased by its geographical location.\n\n\nCode\nplt.figure(figsize=(10, 5))\nsns.countplot(data=data, x='Region', order=data['Region'].value_counts().index, color=\"tab:green\")\nplt.title(\"Number of Well in Each Region\")\nplt.show()\n\n\n\n\n\nFigure 1: Number of well in each region\n\n\n\n\n\n\nNumber of Well from Each Water Type\nHowever, there are higher number of well with undrinkable water (AS) in comparison to well with drinkable water (ASAM). This disproportion emphasizes a significant concern regarding the availability of safe drinking water sources in the regions of Bandung, as a considerably larger proportion of the wells are observed to exhibit water quality issues.\n\n\nCode\nplt.figure(figsize=(8, 5))\nsns.countplot(data=data, x='Type')\nplt.title(\"Number of Well from Each Water Type\")\nplt.show()\n\n\n\n\n\nFigure 2: Number of Well from Each Water Type\n\n\n\n\n\n\nNumber of Well in Each Region by Water Type\nWhile several regions like Pacet and Pangalengan already have more drinkable-water wells than undrinkable ones, most of the regions still grapple with a concerning disparity. In these areas, the amount of undrinkable-water wells not only surpasses their drinkable counterparts but does so by a substantial margin.\n\n\nCode\nplt.figure(figsize=(10, 5))\nsns.countplot(x='Region',\n              data=data,\n              order=['BL', 'CP', 'MJ', 'PC', 'PL', 'RC', 'SR'],\n              hue='Type')\nplt.title(\"Number of Well in Each Region by Water Type\")\nplt.show()\n\n\n\n\n\nFigure 3: Number of Well in Each Region by Water Type\n\n\n\n\n\n\nMean of Substances Concentration in Each Region\nIn any region, calculated by the mean of concentration, three substances dominates among another: iron (Fe), manganese (Mn), and zinc (Zn). In most of the regions, wells are heavily contaminated by iron. Some exceptions are Pacet and Pangalengan, where the wells are contaminated dominantly by manganese, and Soreang, where the wells are contaminated by iron and manganese equally.\n\n\nCode\ndata_gp = data.iloc[:, 1:-1].groupby(['Region']).agg('mean')\nres = data_gp.reset_index()\nres_wide = res.melt(id_vars=\"Region\")\n\nplt.figure(figsize=(12, 9.5))\nsns.barplot(x=\"Region\", y=\"value\", data=res_wide, hue='variable')\nplt.title('Mean of Substances Concentration in Each Region')\nplt.ylabel('')\nplt.show()\n\n\n\n\n\nFigure 4: Mean of Substances Concentration in Each Region\n\n\n\n\n\n\nMean of Substances Concentration in Each Region (AS/ASAM Only)\nIf we take a look back at Figure 3, Pacet and Pangalengan are the only region that have more drinkable-water water source than the undrinkable one. This may suggest that low level of iron (or high level of manganese) contamination is one of the indicator for a healthy, drinkable water.\nHowever, if we look at the next two plots, where these are similar to Figure 4 but separated by the water type, there are undrinkable water with high level of manganese as well as drinkable water with high level of iron. Therefore, at least for now, neither manganese contamination level nor iron contamination level can be considered as an indicator of undrinkable water.\n\n\nCode\ndata_gp = data[data['Type'] == 'AS'].iloc[:, 1:-1].groupby(['Region']).agg('mean')\nres = data_gp.reset_index()\nres_wide=res.melt(id_vars=\"Region\")\n\nplt.figure(figsize=(12,9.5))\nsns.barplot(x=\"Region\", y=\"value\",data=res_wide, hue='variable')\nplt.title('Mean of Substances Concentration in Each Region (AS Only)')\nplt.ylabel('')\nplt.ylim(0, 2.5)\nplt.show()\n\ndata_gp = data[data['Type'] == 'ASAM'].iloc[:, 1:-1].groupby(['Region']).agg('mean')\nres = data_gp.reset_index()\nres_wide=res.melt(id_vars=\"Region\")\n\nplt.figure(figsize=(12,9.5))\nsns.barplot(x=\"Region\", y=\"value\",data=res_wide, hue='variable')\nplt.title('Mean of Substances Concentration in Each Region (ASAM Only)')\nplt.ylabel('')\nplt.ylim(0, 2.5)\nplt.show()\n\n\n\n\n\n\n\n\n(a) (AS Only)\n\n\n\n\n\n\n\n(b) (ASAM Only)\n\n\n\n\nFigure 5: Mean of Substances Concentration in Each Region"
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#multivariate-eda",
    "href": "posts/well_water/well_water_analysis.html#multivariate-eda",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Multivariate EDA",
    "text": "Multivariate EDA\n\nSubstances Concentration Variable\nRegarding the variables related to substances concentration, every single one of them has a positive skewed distribution. Because the plot for all 10 substances is too large, as an example, I will only show the distribution of three variable along with the correlation between each two of them.\nAs for the results, there isn’t any notable result except for the fact that the Cadmium (Cd) and Lead (Pb) are highly correlated. Deeper knowledge about chemistry and water engineering might be needed to gain meaningful insights from this result.\n\n\nCode\nfrom scipy.stats import pearsonr\n\ndef corrfunc(x, y, ax=None, hue=None, **kws):\n    \"\"\"Plot the correlation coefficient in the top left hand corner of a plot.\"\"\"\n    r, _ = pearsonr(x, y)\n    ax = ax or plt.gca()\n    ax.annotate(f'ρ = {r:.2f}', xy=(.1, .9), xycoords=ax.transAxes)\n\ng = sns.pairplot(data=data[['Pb', 'Cd', 'Hg', 'Type']], hue='Type', diag_kind='hist')\ng.map_lower(corrfunc)\nplt.show()\n\n\n\n\n\nFigure 6: Distribution of 3 (out of 10) substance along with correlation between each two of them"
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#methods",
    "href": "posts/well_water/well_water_analysis.html#methods",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Methods",
    "text": "Methods\nIn this analysis, I will specifically use hierarchical clustering method with four kinds of linkage:\n\nSingle linkage, where the distance of two clusters A and B is defined with the minimum distance between a point in A and a point in B. \\[\n{\\displaystyle \\min _{a\\in A,\\,b\\in B}d(a,b)}\n\\tag{1}\\]\nComplete linkage, where the distance of two clusters A and B is defined with the maximum distance between a point in A and a point in B. \\[\n{\\displaystyle \\max _{a\\in A,\\,b\\in B}d(a,b)}\n\\] {#complete-linkage}\nAverage linkage, where the distance between two clusters A and B is defined as the average of the distances between every points in A and every points in B. \\[\n{\\displaystyle {\\frac {1}{|A|\\cdot |B|}}\\sum _{a\\in A}\\sum _{b\\in B}d(a,b)}\n\\] {#average-linkage}\nWard’s linkage, where at each step, it joins two clusters A and B that minimize the increase in SSE (sum-squared error) defined as below. \\[\nSSE = \\sum _{x\\in A\\cup B}\\lVert x-\\mu _{A\\cup B}\\rVert ^{2}-\\sum _{x\\in A}\\lVert x-\\mu _{A}\\rVert ^{2}-\\sum _{x\\in B}\\lVert x-\\mu _{B}\\rVert ^{2}\n\\] {#ward-linkage}\n\nNote that at each step in single linkage, complete linkage, and average linkage, they join the two clusters with the smallest distance, as measured with the respective distance definition.\nIn python, you can perform hierarchical analysis by utilizing the functions offered by the SciPy package.\n\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are not familiar yet with the concept of hierarchical clustering, I suggest you to read this article and this wikipedia page."
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#number-of-cluster",
    "href": "posts/well_water/well_water_analysis.html#number-of-cluster",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Number of Cluster",
    "text": "Number of Cluster\nFrom previous EDA, we have seen that the data often can be divided into three categories. For example, in Figure 3, we can categorize the data like this\n\nregion where the number of AS well-water is more than ASAM water,\nregion where the number of ASAM well-water is more than AS, and\nregion where the number of AS well-water and ASAM well-water are equal.\n\nAnother example is present in figure 8, where we can categorize the data like this 1. region where the concentration mean of iron is higher than manganese, 2. region where the concentration mean of manganese is higher than iron, and 3. region where the concentration mean of iron and manganese are equal.\nTherefore, given the results of what we’ve explored (that sugggests there is an inherent structure and pattern in the data), I will choose three as the number of cluster in this analysis. Of course, these categorization may seems arbitrary (indeed they are). However, as we will see in the clustering result, the selection of three clusters is not a bad decision."
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#aggregation",
    "href": "posts/well_water/well_water_analysis.html#aggregation",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Aggregation",
    "text": "Aggregation\nThe clustering process will be based on the substances concentrations value at each region. Because one region contains several wells, we need to aggregate them first. In this analysis I use the mean aggregation. You can see the result as below.\n\n\nCode\ndata = data.iloc[:, 1:-1]\nagg_mean = data.groupby('Region').agg('mean')\nagg_mean\n\n\n\n\n\n\n\nTable 5: Aggregated Data\n\n\n\nAs\nCd\nCo\nCr\nCu\nFe\nHg\nMn\nPb\nZn\n\n\nRegion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBL\n0.011117\n0.001004\n0.001029\n0.008858\n0.014692\n0.973554\n0.013504\n0.377721\n0.009838\n0.455558\n\n\nCP\n0.012358\n0.000517\n0.000938\n0.014554\n0.013850\n1.534404\n0.000308\n0.711413\n0.007667\n0.130892\n\n\nMJ\n0.008978\n0.001396\n0.000778\n0.008219\n0.008593\n1.746515\n0.000100\n0.500022\n0.019404\n0.112393\n\n\nPC\n0.012085\n0.000790\n0.001235\n0.009540\n0.011375\n0.461930\n0.000100\n1.225370\n0.013360\n0.048860\n\n\nPL\n0.009483\n0.000633\n0.002061\n0.009728\n0.009356\n0.269589\n0.008478\n0.775944\n0.005300\n0.252650\n\n\nRC\n0.013460\n0.001476\n0.000780\n0.011820\n0.009332\n0.999200\n0.000100\n0.658616\n0.029140\n0.143132\n\n\nSR\n0.009836\n0.001145\n0.001818\n0.006677\n0.005350\n0.718868\n0.004595\n0.833150\n0.018445\n0.156645"
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#results-dendrogram",
    "href": "posts/well_water/well_water_analysis.html#results-dendrogram",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Results (Dendrogram)",
    "text": "Results (Dendrogram)\nAfter applying the four clustering methods to the aggregated data, we achieve four dendrograms for each methods.\nAccording to the single method, we can see that CP with MJ are the most similar ones, therefore they might be belong to the same cluster. On the other side, we can also see that RC and SR are similar, so they might have their own cluster too. The next point that is closer to RC and SR is BL, followed by PL and PC.\n\n\nCode\nagg_mean = data.groupby('Region').agg('mean')\nZ = linkage(agg_mean, 'single')\nfig = plt.figure(figsize=(25, 10))\ndn = dendrogram(Z, labels=agg_mean.index)\nplt.title('Single')\nplt.show()\n\n\n\n\n\nFigure 7: Dendrogram of Single Ward Method\n\n\n\n\nIn fact, if we look at the next three dendrogram resulting from the average linkage, complete linkage, and ward linkage, we can see the similar pattern with only a slight difference. In these three methods, BL-RC-SR cluster are joined with the PC-PL cluster, rather than joined with PL and then PC like we have seen from the single linkage.\n\n\nCode\nZ = linkage(agg_mean, 'average')\nfig = plt.figure(figsize=(25, 10))\ndn = dendrogram(Z, labels=agg_mean.index)\nplt.title('Average')\nplt.show()\n\n\n\n\n\nFigure 8: Dendrogram of Average Method\n\n\n\n\n\n\nCode\nZ = linkage(agg_mean, 'complete')\nfig = plt.figure(figsize=(25, 10))\ndn = dendrogram(Z, labels=agg_mean.index)\nplt.title('Complete')\nplt.show()\n\n\n\n\n\nFigure 9: Dendrogram of Complete Method\n\n\n\n\n\n\nCode\nZ = linkage(agg_mean, 'ward')\nfig = plt.figure(figsize=(25, 10))\ndn = dendrogram(Z, labels=agg_mean.index)\nplt.title('Ward')\nplt.show()\n\n\n\n\n\nFigure 10: Dendrogram of Ward Method"
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#assign-cluster-for-each-region",
    "href": "posts/well_water/well_water_analysis.html#assign-cluster-for-each-region",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Assign Cluster for Each Region",
    "text": "Assign Cluster for Each Region\nHere we create new column that indicates which cluster each well belongs to (according to the region).\n\n\nCode\ncluster_raw_single = {\"CP|MJ\":1, \"PC\":2, \"PL|BL|RC|SR\":3}\ndata['Single'] = data['Region'].replace(cluster_raw_single, regex=True)\n\ncluster_raw_avg = {\"CP|MJ\":1, \"BL|RC|SR\":2, \"PC|PL\":3}\ndata['Others'] = data['Region'].replace(cluster_raw_avg, regex=True)\n\n# make it recognized as a category\ndata['Single'] = data['Single'].astype('object')\ndata['Others'] = data['Others'].astype('object')\n\n\n\n\n\n\n\n\n\nTable 6: Data After Cluster Assignment\n\n\n\nAs\nCd\nCo\nCr\nCu\nFe\nHg\nMn\nPb\nZn\nRegion\nSingle\nOthers\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n0.0062\n0.0001\n0.0026\n0.0069\n0.0100\n1.6585\n0.0001\n0.3428\n0.0001\n0.1079\nMJ\n1\n1\n\n\n2\n0.0212\n0.0006\n0.0001\n0.0070\n0.0077\n3.7910\n0.0001\n0.4119\n0.0119\n0.0309\nMJ\n1\n1\n\n\n3\n0.0065\n0.0001\n0.0001\n0.0062\n0.0073\n0.0820\n0.0001\n0.2206\n0.0186\n0.0521\nMJ\n1\n1\n\n\n4\n0.0162\n0.0006\n0.0001\n0.0084\n0.0094\n1.4833\n0.0001\n0.4985\n0.0001\n0.0886\nMJ\n1\n1\n\n\n5\n0.0194\n0.0001\n0.0001\n0.0086\n0.0098\n2.3356\n0.0001\n0.1716\n0.0196\n0.0641\nMJ\n1\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n156\n0.0164\n0.0001\n0.0001\n0.0059\n0.0024\n0.3552\n0.0001\n0.0012\n0.0001\n0.0739\nSR\n3\n2\n\n\n157\n0.0196\n0.0019\n0.0171\n0.0053\n0.0125\n0.1067\n0.0001\n0.7120\n0.0495\n0.8312\nSR\n3\n2\n\n\n158\n0.0062\n0.0001\n0.0085\n0.0076\n0.0089\n0.0684\n0.0001\n1.1956\n0.0235\n0.0755\nSR\n3\n2\n\n\n159\n0.0070\n0.0001\n0.0015\n0.0072\n0.0033\n0.0547\n0.0050\n0.1624\n0.0001\n0.0606\nSR\n3\n2\n\n\n160\n0.0110\n0.0001\n0.0002\n0.0054\n0.0021\n0.0826\n0.0001\n0.0058\n0.0001\n0.8351\nSR\n3\n2\n\n\n\n\n\n160 rows × 13 columns"
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#assign-longitude-and-latitude",
    "href": "posts/well_water/well_water_analysis.html#assign-longitude-and-latitude",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Assign Longitude and Latitude",
    "text": "Assign Longitude and Latitude\nTo support our consideration, let’s take a look at how these cluster represents the regions in geographical perspective.\nIt’s not hard to acquire longitude and latitude data for each region. I manually input them from Google Maps. For the plotting, I use Plotly Express.\n\n\nCode\nreplacer_long = {\"MJ\": 107.746994, \"BL\": 107.631878, \"RC\": 107.759404, \"SR\": 107.532008, \"PL\": 107.566423, \"PC\": 107.698135, \"CP\": 107.710501}\nreplacer_lat = {\"MJ\": -7.054680, \"BL\": -7.004517, \"RC\": -6.971517, \"SR\": -7.025404, \"PL\": -7.195907, \"PC\": -7.119608, \"CP\": -7.037803}\ndata['longitude'] = data['Region'].replace(replacer_long).astype(float)\ndata['latitude'] = data['Region'].replace(replacer_lat).astype(float)"
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#final-data",
    "href": "posts/well_water/well_water_analysis.html#final-data",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Final Data",
    "text": "Final Data\n\n\n\n\n\n\n\nTable 7: Final Form of The Data\n\n\n\nAs\nCd\nCo\nCr\nCu\nFe\nHg\nMn\nPb\nZn\nRegion\nSingle\nOthers\nlongitude\nlatitude\n\n\nNo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n0.0062\n0.0001\n0.0026\n0.0069\n0.0100\n1.6585\n0.0001\n0.3428\n0.0001\n0.1079\nMJ\n1\n1\n107.746994\n-7.054680\n\n\n2\n0.0212\n0.0006\n0.0001\n0.0070\n0.0077\n3.7910\n0.0001\n0.4119\n0.0119\n0.0309\nMJ\n1\n1\n107.746994\n-7.054680\n\n\n3\n0.0065\n0.0001\n0.0001\n0.0062\n0.0073\n0.0820\n0.0001\n0.2206\n0.0186\n0.0521\nMJ\n1\n1\n107.746994\n-7.054680\n\n\n4\n0.0162\n0.0006\n0.0001\n0.0084\n0.0094\n1.4833\n0.0001\n0.4985\n0.0001\n0.0886\nMJ\n1\n1\n107.746994\n-7.054680\n\n\n5\n0.0194\n0.0001\n0.0001\n0.0086\n0.0098\n2.3356\n0.0001\n0.1716\n0.0196\n0.0641\nMJ\n1\n1\n107.746994\n-7.054680\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n156\n0.0164\n0.0001\n0.0001\n0.0059\n0.0024\n0.3552\n0.0001\n0.0012\n0.0001\n0.0739\nSR\n3\n2\n107.532008\n-7.025404\n\n\n157\n0.0196\n0.0019\n0.0171\n0.0053\n0.0125\n0.1067\n0.0001\n0.7120\n0.0495\n0.8312\nSR\n3\n2\n107.532008\n-7.025404\n\n\n158\n0.0062\n0.0001\n0.0085\n0.0076\n0.0089\n0.0684\n0.0001\n1.1956\n0.0235\n0.0755\nSR\n3\n2\n107.532008\n-7.025404\n\n\n159\n0.0070\n0.0001\n0.0015\n0.0072\n0.0033\n0.0547\n0.0050\n0.1624\n0.0001\n0.0606\nSR\n3\n2\n107.532008\n-7.025404\n\n\n160\n0.0110\n0.0001\n0.0002\n0.0054\n0.0021\n0.0826\n0.0001\n0.0058\n0.0001\n0.8351\nSR\n3\n2\n107.532008\n-7.025404\n\n\n\n\n\n160 rows × 15 columns"
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#plot-according-to-geographical-data",
    "href": "posts/well_water/well_water_analysis.html#plot-according-to-geographical-data",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Plot According to Geographical Data",
    "text": "Plot According to Geographical Data\nRemember that we have two distinct results: one from single method, one from the other methods. Here is both results plotted on a map (it’s interactive!).\n\n\nCode\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\n\n\n\nCode\nimport plotly.express as px\nimport plotly.graph_objects as go\n\ndata_agg = data.groupby(['Region']).agg('mean')\n\nfig = px.scatter_mapbox(data_agg, \n                        lat=\"latitude\", \n                        lon=\"longitude\", \n                        color=\"Single\",\n                        color_discrete_sequence=px.colors.qualitative.G10,\n                        zoom=8,\n                        height=500,\n                        width=700,\n                        text = list(data_agg.index))\n\nfig.update_layout(mapbox_style=\"carto-positron\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.update_traces(marker={'size': 15})\nfig.update_traces(textposition='top center')\nfig.show()\n\n\n\n\n                                                \nFigure 11: Clustering Result Based on Single Method\n\n\n\n\n\nCode\nfig = px.scatter_mapbox(data_agg, \n                        lat=\"latitude\", \n                        lon=\"longitude\", \n                        color='Others',\n                        color_discrete_sequence=px.colors.qualitative.G10,\n                        hover_data={'index': (data_agg.index)},\n                        zoom=8,\n                        height=500,\n                        width=700)\n\nfig.update_layout(mapbox_style=\"carto-positron\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.update_traces(marker={'size': 15})\nfig.show()\n\n\n\n\n                                                \nFigure 12: Clustering Result Based on Others Method\n\n\n\nComparing these two results, I personally prefer the second one, where the regions are separated by latitude coordinate. It is intuitive and easy to interpret. However, we might need more data to make a clear conclusion, such as altitude and water distribution network."
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#clustering-summary",
    "href": "posts/well_water/well_water_analysis.html#clustering-summary",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Clustering Summary",
    "text": "Clustering Summary\nTo summarize the preceding results, Ciparay (CP) and Majalengka (MJ) are always joined first resulting in CP-MJ cluster. In all four results, this CP-MJ cluster consistently joined last with a cluster containing the rest of the regions.\nOn the other side, Rancaekek (RC) and Soreang (SR) are always be the second points joined then resulting in RC-SR cluster. After that, this RC-SR cluster will always be joined with Baleendah (BL) resulting in RC-SR-BL cluster. In the single linkage result, the RC-SR-BL cluster is joined with Pangalengan (PL), resulting in RC-SR-BL-PL cluster, then joined with Pacet (PC), resulting in RC-SR-BL-PL-PC cluster. However, in other three results, PC and PL are joined first resulting in PC-PL cluster, then joined with the RC-SR-BL cluster, resulting RC-SR-BL-PL-PC cluster."
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#recommendation",
    "href": "posts/well_water/well_water_analysis.html#recommendation",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Recommendation",
    "text": "Recommendation\nAs we mentioned before, we will choose to divide regions into three clusters. There are two different clustering results that can be derived:\n\nCP-MJ cluster, SR-RC-BL-PL cluster, PC cluster (single linkage)\nCP-MJ cluster, SR-RC-BL cluster, PC-PL cluster (other linkages) Based on our previous analysis, I recommend the second clustering result. Why? Firstly, because it is resulted from three different linkage methods, while the first clustering is resulted only from the single linkage method. Secondly, it is supported by geographical data: the second clustering has more intuitive and reasonable distinction based on each regions’ location; also it is more interpretable."
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#conclusion",
    "href": "posts/well_water/well_water_analysis.html#conclusion",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the clustering analysis performed in this study has successfully achieved the first objective by grouping well water sources in Bandung into clusters with similar water quality profiles. With our results, we have gained valuable insights into the regional trends that define the well water structure in Bandung. These clusters also provide a clearer understanding of the geographical factors that influence water quality, allowing the government agencies and institutions to produce more precise targeting of treatment strategies.\nMoving forward, this knowledge will also encourage society to promote public health and environmental awareness, especially in the quality of well water for the residents of Bandung."
  },
  {
    "objectID": "posts/well_water/well_water_analysis.html#reference",
    "href": "posts/well_water/well_water_analysis.html#reference",
    "title": "Hierarchical Clustering Analysis of Well Water Quality in Bandung",
    "section": "Reference",
    "text": "Reference\nA.C Rencher. (2002). Methods of Multivariate Analysis 2nd Edition."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Hey there👋! Welcome to my digital sanctuary—a space where I pour my thoughts, interests, and concerns.\nHere, you’ll find an array of data analysis and machine learning projects. While I’m venturing into the data industry without prior experience, this platform can be viewed as a portfolio of mine, illustrating my capabilities and what I’ve achieved so far.\nHowever, this site isn’t just a portfolio; it’s my sanctuary, a collection of my mind’s wanderings. From data projects to my regular contemplative writing (coming soon!), this space captures my journey of exploration and discovery.\nI’ll primarily use Indonesian  in my writings because it allows me to express myself more freely in my native language. However, I’ll occasionally write in English  as I’m still learning the language and aim to connect with a broader audience.\nCurious to know more about me? Please visit my About page."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a mathematics freshgraduate (B.Sc) who have recently graduated from Institut Teknologi Bandung. Previously, I served as a teaching assistant at Pacmann Academy, an edtech company specializing in Data Science courses. During my one-year at Pacmann, I primarily taught Programming and Mathematics classes.\nPresently, I am not engaged in any formal employment. However, I am actively enhancing my skill set by pursuing new learning opportunities and undertaking various projects. Additionally, this transitional period has afforded me the chance to delve deeper into emerging industry trends and innovative methodologies. Embracing this phase as an opportunity for self-discovery, I am actively building a robust foundation to excel in future professional journey."
  },
  {
    "objectID": "about.html#bio",
    "href": "about.html#bio",
    "title": "About",
    "section": "",
    "text": "I am a mathematics freshgraduate (B.Sc) who have recently graduated from Institut Teknologi Bandung. Previously, I served as a teaching assistant at Pacmann Academy, an edtech company specializing in Data Science courses. During my one-year at Pacmann, I primarily taught Programming and Mathematics classes.\nPresently, I am not engaged in any formal employment. However, I am actively enhancing my skill set by pursuing new learning opportunities and undertaking various projects. Additionally, this transitional period has afforded me the chance to delve deeper into emerging industry trends and innovative methodologies. Embracing this phase as an opportunity for self-discovery, I am actively building a robust foundation to excel in future professional journey."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "The Notebook",
    "section": "",
    "text": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis\n\n\n\n\n\n\n\nproject\n\n\npresentation\n\n\nvisualization\n\n\nanalysis\n\n\n\n\nWhat insights can we extract from the data?\n\n\n\n\n\n\nOct 27, 2023\n\n\nRafi Naufal Aziz\n\n\n\n\n\n\n  \n\n\n\n\nTop 100 Most Subscribed Indonesian Youtubers: Data Scraping\n\n\n\n\n\n\n\nproject\n\n\nscraping\n\n\ncleaning\n\n\n\n\nScrap top 100 youtubers data from SocialBlade and clean it before processed into analysis part.\n\n\n\n\n\n\nOct 26, 2023\n\n\nRafi Naufal Aziz\n\n\n\n\n\n\n  \n\n\n\n\nHierarchical Clustering Analysis of Well Water Quality in Bandung\n\n\n\n\n\n\n\nproject\n\n\nclustering\n\n\n\n\nCan well water sources in Bandung be grouped into clusters with similar water quality profiles?\n\n\n\n\n\n\nOct 12, 2023\n\n\nRafi Naufal Aziz\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#objective-1",
    "href": "posts/youtube_analysis/youtube_analysis.html#objective-1",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "Objective",
    "text": "Objective\n\n\n\nData exploration: Explore some basic descriptive statistics of the data\nTrends identification: Identify what kind of channels are popular in the past three years\nGrowth analysis: Identify the most growing channels, calculated by monthly gained subs\nContent-creation strategy examination: Examine what are the possible strategies used by the top growing channels to gain subscribers or viewers"
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#data-description-1",
    "href": "posts/youtube_analysis/youtube_analysis.html#data-description-1",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "Data Description",
    "text": "Data Description\nData are collected from SocialBlade using data scraping technique. It has 11 columns:\n\nname: The channel’s name\nupload_count: The number of uploaded content\nsubscribers (million): The number of subscribers\nviews: Total views from all uploaded videos\nviews/video: Total views divided by upload count\ntag: The main category of the channel\ndate_created: The channel’s creation date\nage: Age of the channel (in November 2023)\ndate: Monthly date indicating when the views and subs were gained\nviews_gained: Number of views gained each month\nsubs_gained: Number of subscribers gained each month\n\nI wrote a full details about the data collection process and how I cleaned it."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#notes",
    "href": "posts/youtube_analysis/youtube_analysis.html#notes",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "Notes",
    "text": "Notes\nCharts are interactive:\n\nClick on legend label to exclude it from the chart\nDouble click on the legend label to isolate that label\nHover into a point in the chart to see more details\nDrag or click on the chart to zoom in\nDouble click on the chart to zoom out\n\nLet’s begin!"
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-are-the-primary-categories-represented-among-the-top-100-channels",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-are-the-primary-categories-represented-among-the-top-100-channels",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What are the primary categories represented among the top 100 channels?",
    "text": "What are the primary categories represented among the top 100 channels?\n\n\n\n                                                \n\n\n\nEntertainment asserts its dominance with 40 channels, followed by Games, People, and Film categories with 14, 11, and 10 channels, respectively. These four categories alone already represented 75% of the top 100 channels.\nThe rest of the categories demonstrate a smaller but notable presence with 6 or fewer channels each. This highlights the diversity of content on the Indonesian YouTube platform."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#how-the-amount-of-subscribers-are-distributed-across-the-channels",
    "href": "posts/youtube_analysis/youtube_analysis.html#how-the-amount-of-subscribers-are-distributed-across-the-channels",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "How the amount of subscribers are distributed across the channels?",
    "text": "How the amount of subscribers are distributed across the channels?\n\n\n\n                                                \n\n\n\nOverall, in addition to its dominance in terms of proportion, the Entertainment category dominates again in terms of subscribers distribution. Although Games, People, and Film category appears a lot in the list, they are more evenly distributed than Entertainment category.\nMoreover, the distribution looks exponentially decayed. To gain more information, let’s plot the cumulative sum."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#how-the-amount-of-subscribers-are-distributed-across-the-channels-1",
    "href": "posts/youtube_analysis/youtube_analysis.html#how-the-amount-of-subscribers-are-distributed-across-the-channels-1",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "How the amount of subscribers are distributed across the channels?",
    "text": "How the amount of subscribers are distributed across the channels?\n\n\n\n                                                \n\n\n\nFrom this chart, we can infer some information:\n\nA quarter (25%) of total subscribers are subscribed to the top 12 channels\nHalf (50%) of total subscribers are subscribed to the top 33 channels\n\nIt reveals insight into the concentration of audience distribution among top channels. It shows how a minority of channels significantly hold a substantial portion of the overall subscriber."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-kind-of-channels-are-the-most-active",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-kind-of-channels-are-the-most-active",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What kind of channels are the most active?",
    "text": "What kind of channels are the most active?\n\n\n\n                                                \n\n\n\nFrom the chart, we can see that TV channels are the most active content makers. They can upload tens to hundreds thousand of contents (it’s 100x more than most channel in this list).\nThis dominance might stem from their established infrastructure, dedicated production teams, and access to diverse resources. With the resources, they are able to generate content on a large scale, maintaining a consistent stream of uploads."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-kind-of-channels-are-the-most-efficient",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-kind-of-channels-are-the-most-efficient",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What kind of channels are the most efficient?",
    "text": "What kind of channels are the most efficient?\n\n\n\n                                                \n\n\n\nIt appears that the most efficient channels come from kids channel like Zuni and Family, Aishwa Nahla Official, and Like Nastya IDN, that on average gaining more than 10M views per content.\nIf we compare this chart to the previous one, we can see that although TV channels are the most active content makers, they are not efficient. On average, they only gain around 100k views per content."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#when-were-the-channels-created",
    "href": "posts/youtube_analysis/youtube_analysis.html#when-were-the-channels-created",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "When were the channels created?",
    "text": "When were the channels created?\n\n\n\n                                                \n\n\n\nMost top channels are created between 2014 and 2020.\nMost recent channels are Yuni Ara (7.91M subs) and Klara Tania (14.5M subs) that were created in 2021. Oldest channels are Upin & Ipin (9.28M subs) and Raditya Dika (10.1M subs) that were created in 2007."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-trending-categories",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-trending-categories",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What are the most trending categories?",
    "text": "What are the most trending categories?\n\nby average gained subsby average gained views\n\n\n\n\n\n                                                \n\n\n\nOn average, each category maintains a consistent rate of subscriber growth every month. However, there are three categories that stand out from the rest: People, Film, and Entertainment. These categories are gaining more subscribers in recent months compared to their previous months’ gains.\n\n\n\n\n\n\n                                                \n\n\n\nIn general, monthly gained views at each category are unpredictable and tend to fluctuate. However, News and Education category are the only ones that consistently gained around 100M viewers every month.\nAlso if you notice, there are several months where gained views are negative in that month. This can be happened if some videos are taken down by Youtube, or it’s just deleted by the channel. This leads to a ‘negative’ net views from the previous month."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-subs",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-subs",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What are the most growing channels? (by gained subs)",
    "text": "What are the most growing channels? (by gained subs)\n\n\n\n                                                \n\n\n\nFive most growing channel (in terms of gained subs) in the last three years are presented on the chart. Among the five, two come from Entertainment, two from People, and one from Games. For the newcomers (Willie Salim and Vilmei), their rapid growth started from early 2022. Conversely, the remaining three channels began their growth only in the recent months of 2023."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-subs-1",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-subs-1",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What are the most growing channels? (by gained subs)",
    "text": "What are the most growing channels? (by gained subs)\n\n\n\n                                                \n\n\n\nNot only Willie Salim and Vilmei gained many subscribers in the recent three years: They did so with zero1 subscribers at the start! While impressive, it’s not entirely unexpected because they already have many followers on their TikTok account.\n\n\nnotes\n\n\n\n\nThe bar chart overestimates the initial value because it’s calculated from the difference between all time total subs and total subs from the past 3 years. However, the data for November monthly subs aren’t available yet. So the value on the bar chart includes the partial subs gained from November 2023."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-in-each-category",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-in-each-category",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What are the most growing channels in each category?",
    "text": "What are the most growing channels in each category?\n\nEntertainmentGamesPeopleEducationComedyNewsHowtoFilmMusicTechAnimals"
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-views",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-views",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What are the most growing channels? (by gained views)",
    "text": "What are the most growing channels? (by gained views)\n\n\n\n                                                \n\n\n\nWe can see that there are two News channels on the chart. We know they will be on the list because they upload at a very high frequency. Let’s remove them so we can get the actual youtubers who get most viewers in the past three years."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-views-1",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-views-1",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What are the most growing channels? (by gained views)",
    "text": "What are the most growing channels? (by gained views)\n\n\n\n                                                \n\n\n\nAfter removed News channels, five most growing channel (in terms of gained views) in the last three years are presented on the chart. Among the five, two come from Film, one from Education, one from People, and one from Comedy. Interestingly, the two Film channels are newcomers. They rapidly gaining views right after they started making content in mid 2021."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-views-2",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-are-the-most-growing-channels-by-gained-views-2",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What are the most growing channels? (by gained views)",
    "text": "What are the most growing channels? (by gained views)\n\n\n\n                                                \n\n\n\nWe see the similar pattern as before, where two of the most growing channels were starting from zero1! The difference here is that Klara Tania and Ale Khin had smaller fanbase on TikTok compared to Willie Salim and Vilmei.\n\n\nnotes\n\n\n\n\nThe bar chart overestimates the initial value because it’s calculated from the difference between all time total views and total views from the past 3 years. However, the data for November monthly views aren’t available yet. So the value on the bar chart includes the partial views gained from November 2023."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#are-the-most-efficient-channels-still-popular",
    "href": "posts/youtube_analysis/youtube_analysis.html#are-the-most-efficient-channels-still-popular",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "Are the most efficient channels still popular?",
    "text": "Are the most efficient channels still popular?\n\nBy subsBy views\n\n\n\n\n\n                                                \n\n\n\nWhile these channels’ efficiency, measured in views per upload, has traditionally been high, there has been a gradual decline in their popularity in the last three years.\n\n\n\n\n\n\n                                                \n\n\n\nWhile these channels’ efficiency, measured in views per upload, has traditionally been high, there has been a gradual decline in their popularity in the last three years."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-is-the-relationship-between-each-pair-of-numeric-variables",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-is-the-relationship-between-each-pair-of-numeric-variables",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What is the relationship between each pair of numeric variables?",
    "text": "What is the relationship between each pair of numeric variables?\n\n\n\n                                                \n\n\n\nIt doesn’t seems there’s any correlated variables here, except for subscribers and views variables that somehow seems correlated. However, we can see that there are many outliers here. If you hover on the outliers, you will see that many of them are TV channels. These channels don’t represent a typical youtubers, so it’s safe to get rid of them from this chart. We will also get rid of Zuni and Family because they behave as an outlier too."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#what-is-the-relationship-between-each-pair-of-numeric-variables-1",
    "href": "posts/youtube_analysis/youtube_analysis.html#what-is-the-relationship-between-each-pair-of-numeric-variables-1",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "What is the relationship between each pair of numeric variables?",
    "text": "What is the relationship between each pair of numeric variables?\n\n\n\n                                                \n\n\n\nNow we can see that:\n\nEfficiency and views are positively correlated\nEfficiency and upload_count are negatively correlated\nViews and subscribers are positively correlated\n\nThe first two points are kinda obvious as we use views to obtain efficiency. The last point tells us that the most subscribed channels are having the most views."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#correlation-coefficient-between-each-pair-of-numeric-variables",
    "href": "posts/youtube_analysis/youtube_analysis.html#correlation-coefficient-between-each-pair-of-numeric-variables",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "Correlation coefficient between each pair of numeric variables",
    "text": "Correlation coefficient between each pair of numeric variables\n\n\n\n                                                \n\n\n\nHere we can see that:\n\nEfficiency and views are positively correlated\nEfficiency and upload_count are negatively correlated\nViews and subscribers are positively correlated\n\nThe first two points are kinda obvious as we use views to obtain efficiency. The last point tells us that the most subscribed channels are having the most views."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#youtube-shorts",
    "href": "posts/youtube_analysis/youtube_analysis.html#youtube-shorts",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "Youtube Shorts",
    "text": "Youtube Shorts\n\n In the last three years, particularly in Indonesia, Youtube Shorts has been widely used to boost audience engagement and channel growth. In our analysis (especially this and this chart), we have seen that Shorts can be utilized effectively by everyone.\n\nJess No Limit recently gained more than 20 million subscribers in 2023 due to his intensity in uploading Shorts content since April 2023.\nRicis, who previously only uploaded several Shorts contents about her family, gained more subscribers after she creates more Shorts contents about general topic (not only her family).\nAlthough Frost Diamond has always been uploading youtube videos consistently, he gained massive amount of subscriber only after he started to actively creating Shorts content.\nKlara Tania and Ale Khin gained billions of viewers from making Shorts contents despite they only started their Youtube career in mid 2021 and have little popularity before it."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#tiktok-stars-go-tube",
    "href": "posts/youtube_analysis/youtube_analysis.html#tiktok-stars-go-tube",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "TikTok stars go Tube",
    "text": "TikTok stars go Tube\n\n Thanks to the success of YouTube Shorts, TikTok stars like Willie Salim and Vilmie are rapidly growing their presence on YouTube. Both have achieved remarkable success within three years.\n\nWillie Salim gained more than 23M subscribers and joined in top 10 most subscribed Indonesian youtubers. Moreover, he achieved that with less than one thousand uploaded contents, which is very low.\nVilmei gained more than 14M subscribers and joined in top 30 most subscribed Indonesian youtubers."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#kids-contents-are-not-that-popular-anymore",
    "href": "posts/youtube_analysis/youtube_analysis.html#kids-contents-are-not-that-popular-anymore",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "Kids contents are not that popular anymore",
    "text": "Kids contents are not that popular anymore\n\n Kids’ YouTube channels have demonstrated exceptional efficiency in terms of views per upload count. However, there has been a slight decrease in their popularity in Indonesia over recent years, as we have seen here."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#it-is-never-too-late",
    "href": "posts/youtube_analysis/youtube_analysis.html#it-is-never-too-late",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "It is never too late",
    "text": "It is never too late\n\n Throughout its history, Youtube has always been a dynamic platform for content creators. If you’re considering diving into content creation, there’s no better time than now. Notably, creators like Yuni Ara, Klara Tania, and Ale Khin were just started they journey in recent years. Their success emphasizes that choosing the right niche with the right strategy will raise the potential to boost your popularity rapidly."
  },
  {
    "objectID": "posts/youtube_analysis/youtube_analysis.html#suggestion-1",
    "href": "posts/youtube_analysis/youtube_analysis.html#suggestion-1",
    "title": "Top 100 Most Subscribed Indonesian Youtubers: Data Analysis",
    "section": "Suggestion",
    "text": "Suggestion\n\n\n\nI suggest to create more Shorts contents, especially for big youtubers, as many of them haven’t utilized this potential feature. They could easily gain millions of subscribers by shifting into producing Shorts contents.\nFor tiktokers, I highly suggest to expand their presence in youtube through youtube shorts. They can gain more audience by uploading the same contents in tiktok and youtube.\nFor the aspiring creators, it’s never too late to start the journey in the content creation industry. Some of the current top youtubers only started their career in the past three years.\n\n\n\n\nhttps://rafinflaziz.github.io/"
  }
]